{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "\n",
    "from Extract_mouse_data import Mouse_sub_volumes\n",
    "from data_augmentation import Rotate, Flip\n",
    "from weight_init import weight_init\n",
    "from my_net import VGG_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Function and class here\n",
    "def get_subbox_idx(input_idx,input_all_data):\n",
    "    sub_box=[]\n",
    "    neg_num=0\n",
    "    pos_num=0\n",
    "    for idx in input_idx:\n",
    "        for i in range(len(input_all_data[idx][0])):\n",
    "            sub_box.append((idx,0,input_all_data[idx][0][i]))\n",
    "        neg_num+=len(input_all_data[idx][0])\n",
    "        for i in range(len(input_all_data[idx][1])):\n",
    "            sub_box.append((idx,1,input_all_data[idx][1][i]))\n",
    "        pos_num+=len(input_all_data[idx][1])\n",
    "    print(neg_num)\n",
    "    print(pos_num)\n",
    "    print(len(sub_box))\n",
    "    return sub_box\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def train(model, device, train_loader, optimizer, criterion, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i_batch, sample_batched in enumerate(train_loader):\n",
    "        inputs, labels = sample_batched['image'], sample_batched['label']  \n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i_batch % 10 == 0:\n",
    "            print(\"epoch {}, batch {}, current loss {}\".format(epoch+1,i_batch,running_loss/10))\n",
    "            running_loss = 0.0\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    correct_num = 0\n",
    "    total_num = 0\n",
    "    positive_correct=0\n",
    "    positive_num=0\n",
    "    negative_correct=0\n",
    "    negative_num=0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i_batch, sample_batched in enumerate(test_loader):\n",
    "            inputs, labels = sample_batched['image'], sample_batched['label']  \n",
    "            inputs = inputs.to(device)\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_num+=np.sum(predicted.cpu().numpy()==labels.numpy())\n",
    "            total_num+=len(labels)\n",
    "            positive_correct+=np.sum(predicted.cpu().numpy()*labels.numpy())\n",
    "            positive_num+=np.sum(labels.numpy())\n",
    "            negative_correct+=np.sum((1-predicted.cpu().numpy())*(1-labels.numpy()))\n",
    "            negative_num+=np.sum(1-labels.numpy())\n",
    "            \n",
    "    print('total_num:{}, test accuracy:{}, positive_acc:{}, negative_acc:{}'.format(total_num,\n",
    "                                                                                   correct_num/total_num,\n",
    "                                                                                    positive_correct/positive_num,\n",
    "                                                                                    negative_correct/negative_num\n",
    "                                                                                    ))\n",
    "    \n",
    "    \n",
    "def test_ensemble(model_list, device, test_loader):\n",
    "    for i in range(len(model_list)):\n",
    "        model_list[i].eval()\n",
    "    #model3.eval()\n",
    "    correct_num = 0\n",
    "    total_num = 0\n",
    "    positive_correct=0\n",
    "    positive_num=0\n",
    "    negative_correct=0\n",
    "    negative_num=0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i_batch, sample_batched in enumerate(test_loader):\n",
    "            inputs, labels = sample_batched['image'], sample_batched['label']  \n",
    "            inputs = inputs.to(device)\n",
    "            # forward + backward + optimize\n",
    "            outputs = torch.nn.functional.softmax(model_list[0](inputs),dim=1)\n",
    "            for i in range(1,len(model_list)):\n",
    "                outputs += torch.nn.functional.softmax(model_list[i](inputs),dim=1)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_num+=np.sum(predicted.cpu().numpy()==labels.numpy())\n",
    "            total_num+=len(labels)\n",
    "            positive_correct+=np.sum(predicted.cpu().numpy()*labels.numpy())\n",
    "            positive_num+=np.sum(labels.numpy())\n",
    "            negative_correct+=np.sum((1-predicted.cpu().numpy())*(1-labels.numpy()))\n",
    "            negative_num+=np.sum(1-labels.numpy())\n",
    "            \n",
    "    print('total_num:{}, test accuracy:{}, positive_acc:{}, negative_acc:{}'.format(total_num,\n",
    "                                                                                   correct_num/total_num,\n",
    "                                                                                    positive_correct/positive_num,\n",
    "                                                                                    negative_correct/negative_num\n",
    "                                                                                    ))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_data(path):\n",
    "    with open(data_path,'rb') as f:\n",
    "        #(neg_subvolumes,pos_subvolumes,img2,filtered_img2,img_label2,data_dic[i][0])\n",
    "        all_data = pickle.load(f)\n",
    "    f.close()\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Training settings\n",
    "    parser = argparse.ArgumentParser(description='PyTorch BV classifier.')\n",
    "    parser.add_argument('--batch_size', type=int, default=100, metavar='N',\n",
    "                        help='input batch size for training (default: 100)')\n",
    "    parser.add_argument('--epochs', type=int, default=7, metavar='N',\n",
    "                        help='number of epochs to train (default: 7)')\n",
    "    parser.add_argument('--lr', type=float, default=0.005, metavar='LR',\n",
    "                        help='learning rate (default: 0.005)')\n",
    "    parser.add_argument('--SGD', action='store_true',\n",
    "                       help='set optimizer as SGD')\n",
    "    parser.add_argument('--Adam', action='store_true'\n",
    "                       help='set optimizer as Adam')\n",
    "    parser.add_argument('--RMSprop', action='store_true'\n",
    "                       help='set optimizer as RMSprop')\n",
    "    parser.add_argument('--save_version', type=int, default=1,\n",
    "                        help='save_version (default 1)')\n",
    "    args = parser.parse_args()\n",
    "    print(\"batch_size: {}, training epochs: {}, learning rate: {}, SGD {}, Adam {}, RMSprop {}, save_version {}\".\n",
    "         format(args.batch_szie, args.epochs, args.lr, args.SGD, args.Adam, args.RMSprop, args.save_version))\n",
    "    \n",
    "    data_path = os.path.join(os.getcwd(),'data','2018_0622_all_sub_volumes.pickle')\n",
    "    all_data = load_data(data_path)\n",
    "    \n",
    "    HALF_SIDE = 64 # half of the bounding size 128\n",
    "    #take 1/6 as test img and the rest as train img\n",
    "    test_idx = list(range(0,len(all_data),6))\n",
    "    total_idx = list(range(len(all_data)))\n",
    "    train_idx = [x for x in total_idx if x not in test_idx]\n",
    "\n",
    "    print(\"test index: {0}\".format(test_idx))\n",
    "    print(\"train index: {0}\".format(train_idx))\n",
    "    \n",
    "    all_whole_volumes = {}\n",
    "    all_whole_filtered_volumes = {}\n",
    "    for i in range(len(all_data)):\n",
    "        all_whole_volumes[i] = all_data[i][2]\n",
    "        all_whole_filtered_volumes[i] = all_data[i][3]\n",
    "        \n",
    "    train_sub_box=get_subbox_idx(train_idx,all_data)\n",
    "    test_sub_box=get_subbox_idx(test_idx,all_data)\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    net = VGG_net()\n",
    "    #net.apply(weight_init)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        net = nn.DataParallel(net)\n",
    "    net.to(device)\n",
    "    print(\"There are {} parameters in the model\".format(count_parameters(net)))\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss(weight=torch.FloatTensor([1,1.2]).to(device))\n",
    "    if args.SGD == True:\n",
    "        optimizer = optim.SGD(net.parameters(), lr=args.lr, momentum=0.9, weight_decay=0.00001)\n",
    "        print('choose SGD as optimizer')\n",
    "    elif args.Adam == True:\n",
    "        optimizer = optim.Adam(net.parameters(), lr=args.lr*10, weight_decay=0.00001)\n",
    "        print('choose Adam as optimizer')\n",
    "    elif args.RMSprop == True:\n",
    "        optimizer = optim.RMSprop(net.parameters(), lr=args.lr*10, weight_decay=0.00001)\n",
    "        print('choose RMSprop as optimizer')\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "    \n",
    "    for epoch in range(args.epochs):\n",
    "        scheduler.step()\n",
    "        Mouse_dataset = Mouse_sub_volumes(all_whole_volumes,all_whole_filtered_volumes,train_sub_box,\n",
    "                                     transform=transforms.Compose([Rotate(),Flip()]))\n",
    "        dataloader = DataLoader(Mouse_dataset, batch_size=args.batch_size,\n",
    "                        shuffle=True, num_workers=4)\n",
    "        train(net, device, dataloader, optimizer, criterion, epoch)\n",
    "    print('Finished Training')\n",
    "    torch.save(net.state_dict(), './model/bv_classifier_b{}_e{}_v{}.pth'.format(args.batch_size,\n",
    "                                                                             args.epochs,\n",
    "                                                                             args.save_version))\n",
    "    #####test\n",
    "    print('train accuracy: ')\n",
    "    Mouse_dataset = Mouse_sub_volumes(all_whole_volumes,all_whole_filtered_volumes,train_sub_box)\n",
    "    train_dataloader = DataLoader(Mouse_dataset, batch_size=args.batch_size,\n",
    "                        shuffle=False, num_workers=4)\n",
    "    test(net, device, train_dataloader)\n",
    "    \n",
    "    print('test accuracy: ')\n",
    "    Mouse_dataset = Mouse_sub_volumes(all_whole_volumes,all_whole_filtered_volumes,test_sub_box)\n",
    "    test_dataloader = DataLoader(Mouse_dataset, batch_size=args.batch_size,\n",
    "                        shuffle=False, num_workers=4)\n",
    "    test(net, device, test_dataloader)\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(os.getcwd(),'data','2018_0622_all_sub_volumes.pickle')\n",
    "all_data = load_data(data_path)\n",
    "    \n",
    "HALF_SIDE = 64 # half of the bounding size 128\n",
    "#take 1/6 as test img and the rest as train img\n",
    "test_idx = list(range(0,len(all_data),6))\n",
    "total_idx = list(range(len(all_data)))\n",
    "train_idx = [x for x in total_idx if x not in test_idx]\n",
    "\n",
    "print(\"test index: {0}\".format(test_idx))\n",
    "print(\"train index: {0}\".format(train_idx))\n",
    "    \n",
    "all_whole_volumes = {}\n",
    "all_whole_filtered_volumes = {}\n",
    "for i in range(len(all_data)):\n",
    "    all_whole_volumes[i] = all_data[i][2]\n",
    "    all_whole_filtered_volumes[i] = all_data[i][3]\n",
    "        \n",
    "train_sub_box=get_subbox_idx(train_idx,all_data)\n",
    "test_sub_box=get_subbox_idx(test_idx,all_data)\n",
    "    \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net1 = VGG_net()\n",
    "net2 = VGG_net()\n",
    "net3 = VGG_net()\n",
    "net4 = VGG_net()\n",
    "net5 = VGG_net()\n",
    "net6 = VGG_net()\n",
    "net7 = VGG_net()\n",
    "#net.apply(weight_init)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    net1 = nn.DataParallel(net1)\n",
    "    net2 = nn.DataParallel(net2)\n",
    "    net3 = nn.DataParallel(net3)\n",
    "    net4 = nn.DataParallel(net4)\n",
    "    net5 = nn.DataParallel(net5)\n",
    "    net6 = nn.DataParallel(net6)\n",
    "    net7 = nn.DataParallel(net7)\n",
    "    \n",
    "net1.to(device)\n",
    "net1.load_state_dict(torch.load('./model/bv_classifier_b200_e5_v8.pth'))\n",
    "net2.to(device)\n",
    "net2.load_state_dict(torch.load('./model/bv_classifier_b200_e5_v9.pth'))\n",
    "net3.to(device)\n",
    "net3.load_state_dict(torch.load('./model/bv_classifier_b200_e7_v3.pth'))\n",
    "net4.to(device)\n",
    "net4.load_state_dict(torch.load('./model/bv_classifier_b200_e7_v4.pth'))\n",
    "net5.to(device)\n",
    "net5.load_state_dict(torch.load('./model/bv_classifier_b200_e7_v5.pth'))\n",
    "net6.to(device)\n",
    "net6.load_state_dict(torch.load('./model/bv_classifier_b200_e7_v6.pth'))\n",
    "net7.to(device)\n",
    "net7.load_state_dict(torch.load('./model/bv_classifier_b200_e7_v7.pth'))\n",
    "net = [net1,net2,net5,net6,net7]\n",
    "print(\"There are {} parameters in the model\".format(count_parameters(net1)))\n",
    "\n",
    "#####test\n",
    "print('test: ')\n",
    "Mouse_dataset = Mouse_sub_volumes(all_whole_volumes,all_whole_filtered_volumes,test_sub_box)\n",
    "test_dataloader = DataLoader(Mouse_dataset, batch_size=200,\n",
    "                        shuffle=False, num_workers=4)\n",
    "#test(net1, device, test_dataloader)\n",
    "#test(net2, device, test_dataloader)\n",
    "test_ensemble(net, device, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dense_net\n",
    "data_path = os.path.join(os.getcwd(),'data','2018_0622_all_sub_volumes.pickle')\n",
    "all_data = load_data(data_path)\n",
    "    \n",
    "HALF_SIDE = 64 # half of the bounding size 128\n",
    "#take 1/6 as test img and the rest as train img\n",
    "test_idx = list(range(0,len(all_data),6))\n",
    "total_idx = list(range(len(all_data)))\n",
    "train_idx = [x for x in total_idx if x not in test_idx]\n",
    "\n",
    "print(\"test index: {0}\".format(test_idx))\n",
    "print(\"train index: {0}\".format(train_idx))\n",
    "    \n",
    "all_whole_volumes = {}\n",
    "all_whole_filtered_volumes = {}\n",
    "for i in range(len(all_data)):\n",
    "    all_whole_volumes[i] = all_data[i][2]\n",
    "    all_whole_filtered_volumes[i] = all_data[i][3]\n",
    "        \n",
    "train_sub_box=get_subbox_idx(train_idx,all_data)\n",
    "test_sub_box=get_subbox_idx(test_idx,all_data)\n",
    "    \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = dense_net.DenseNet()\n",
    "#net.apply(weight_init)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    net = nn.DataParallel(net)\n",
    "net.to(device)\n",
    "print(\"There are {} parameters in the model\".format(count_parameters(net)))\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss(weight=torch.FloatTensor([1,1.2]).to(device))\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9, weight_decay=0.00001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "    \n",
    "for epoch in range(5):\n",
    "    scheduler.step()\n",
    "    Mouse_dataset = Mouse_sub_volumes(all_whole_volumes,all_whole_filtered_volumes,train_sub_box,\n",
    "                                     transform=transforms.Compose([Rotate(),Flip()]))\n",
    "    dataloader = DataLoader(Mouse_dataset, batch_size=100,\n",
    "                        shuffle=True, num_workers=4)\n",
    "    train(net, device, dataloader, optimizer, criterion, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mouse_dataset = Mouse_sub_volumes(all_whole_volumes,all_whole_filtered_volumes,test_sub_box)\n",
    "test_dataloader = DataLoader(Mouse_dataset, batch_size=200,\n",
    "                        shuffle=False, num_workers=4)\n",
    "test(net, device, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mouse_dataset = Mouse_sub_volumes(all_whole_volumes,all_whole_filtered_volumes,train_sub_box)\n",
    "test_dataloader = DataLoader(Mouse_dataset, batch_size=200,\n",
    "                        shuffle=False, num_workers=4)\n",
    "test(net, device, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 200, training epochs: 5, learning rate: 0.01, SGD True, Adam False, RMSprop False, save_version 1\n",
      "test index: [0, 6, 12, 18, 24, 30, 36, 42, 48, 54, 60, 66, 72, 78, 84, 90, 96, 102, 108, 114, 120, 126, 132, 138, 144, 150, 156, 162, 168, 174, 180, 186, 192, 198, 204, 210, 216, 222, 228, 234, 240, 246, 252, 258]\n",
      "train index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258]\n",
      "280233\n",
      "211586\n",
      "491819\n",
      "51630\n",
      "36225\n",
      "87855\n",
      "Let's use 2 GPUs!\n",
      "There are 1408982 parameters in the model\n",
      "choose SGD as optimizer\n",
      "epoch 1, batch 0, current loss 0.7200236320495605\n",
      "epoch 1, batch 1, current loss 0.7233213782310486\n",
      "epoch 1, batch 2, current loss 0.703571081161499\n",
      "epoch 1, batch 3, current loss 0.7389407753944397\n",
      "epoch 1, batch 4, current loss 0.7065622806549072\n",
      "epoch 1, batch 5, current loss 0.7689695954322815\n",
      "epoch 1, batch 6, current loss 0.7422650456428528\n",
      "epoch 1, batch 7, current loss 0.6871442198753357\n",
      "epoch 1, batch 8, current loss 0.7646098136901855\n",
      "epoch 1, batch 9, current loss 0.7324060797691345\n",
      "epoch 1, batch 10, current loss 0.7234721779823303\n",
      "epoch 1, batch 11, current loss 0.7158215045928955\n",
      "epoch 1, batch 12, current loss 0.7007576823234558\n",
      "epoch 1, batch 13, current loss 0.7019416093826294\n",
      "epoch 1, batch 14, current loss 0.7162124514579773\n",
      "epoch 1, batch 15, current loss 0.7195160984992981\n",
      "epoch 1, batch 16, current loss 0.7299108505249023\n",
      "epoch 1, batch 17, current loss 0.7058533430099487\n",
      "epoch 1, batch 18, current loss 0.690007746219635\n",
      "epoch 1, batch 19, current loss 0.6892310380935669\n",
      "epoch 1, batch 20, current loss 0.6896522045135498\n",
      "epoch 1, batch 21, current loss 0.7119917273521423\n",
      "epoch 1, batch 22, current loss 0.6813604235649109\n",
      "epoch 1, batch 23, current loss 0.6764556169509888\n",
      "epoch 1, batch 24, current loss 0.6736903190612793\n",
      "epoch 1, batch 25, current loss 0.7137174606323242\n",
      "epoch 1, batch 26, current loss 0.6785973310470581\n",
      "epoch 1, batch 27, current loss 0.6662191152572632\n",
      "epoch 1, batch 28, current loss 0.6808324456214905\n",
      "epoch 1, batch 29, current loss 0.6817458868026733\n",
      "epoch 1, batch 30, current loss 0.6669282913208008\n",
      "epoch 1, batch 31, current loss 0.6841267347335815\n",
      "epoch 1, batch 32, current loss 0.661064624786377\n",
      "epoch 1, batch 33, current loss 0.6742570400238037\n",
      "epoch 1, batch 34, current loss 0.6376491189002991\n",
      "epoch 1, batch 35, current loss 0.6945403218269348\n",
      "epoch 1, batch 36, current loss 0.6661927700042725\n",
      "epoch 1, batch 37, current loss 0.6571401357650757\n",
      "epoch 1, batch 38, current loss 0.6147477030754089\n",
      "epoch 1, batch 39, current loss 0.6353166103363037\n",
      "epoch 1, batch 40, current loss 0.6413809657096863\n",
      "epoch 1, batch 41, current loss 0.650933027267456\n",
      "epoch 1, batch 42, current loss 0.676954448223114\n",
      "epoch 1, batch 43, current loss 0.6666536927223206\n",
      "epoch 1, batch 44, current loss 0.6201271414756775\n",
      "epoch 1, batch 45, current loss 0.6788175106048584\n",
      "epoch 1, batch 46, current loss 0.5951646566390991\n",
      "epoch 1, batch 47, current loss 0.6237195134162903\n",
      "epoch 1, batch 48, current loss 0.6411488056182861\n",
      "epoch 1, batch 49, current loss 0.6301238536834717\n",
      "epoch 1, batch 50, current loss 0.6350664496421814\n",
      "epoch 1, batch 51, current loss 0.6020190119743347\n",
      "epoch 1, batch 52, current loss 0.6653268933296204\n",
      "epoch 1, batch 53, current loss 0.5894927382469177\n",
      "epoch 1, batch 54, current loss 0.6088091731071472\n",
      "epoch 1, batch 55, current loss 0.6751694083213806\n",
      "epoch 1, batch 56, current loss 0.6172935366630554\n",
      "epoch 1, batch 57, current loss 0.6033862829208374\n",
      "epoch 1, batch 58, current loss 0.5688022375106812\n",
      "epoch 1, batch 59, current loss 0.5708022713661194\n",
      "epoch 1, batch 60, current loss 0.594103991985321\n",
      "epoch 1, batch 61, current loss 0.5806440114974976\n",
      "epoch 1, batch 62, current loss 0.6483182311058044\n",
      "epoch 1, batch 63, current loss 0.6127951741218567\n",
      "epoch 1, batch 64, current loss 0.5698525905609131\n",
      "epoch 1, batch 65, current loss 0.5689862370491028\n",
      "epoch 1, batch 66, current loss 0.6344416737556458\n",
      "epoch 1, batch 67, current loss 0.5674357414245605\n",
      "epoch 1, batch 68, current loss 0.596992552280426\n",
      "epoch 1, batch 69, current loss 0.5807614922523499\n",
      "epoch 1, batch 70, current loss 0.5972958207130432\n",
      "epoch 1, batch 71, current loss 0.565219521522522\n",
      "epoch 1, batch 72, current loss 0.600578784942627\n",
      "epoch 1, batch 73, current loss 0.5281006693840027\n",
      "epoch 1, batch 74, current loss 0.5317195057868958\n",
      "epoch 1, batch 75, current loss 0.5322151780128479\n",
      "epoch 1, batch 76, current loss 0.4998164176940918\n",
      "epoch 1, batch 77, current loss 0.5563174486160278\n",
      "epoch 1, batch 78, current loss 0.5580078363418579\n",
      "epoch 1, batch 79, current loss 0.5160828232765198\n",
      "epoch 1, batch 80, current loss 0.5591404438018799\n",
      "epoch 1, batch 81, current loss 0.5295848846435547\n",
      "epoch 1, batch 82, current loss 0.5336970686912537\n",
      "epoch 1, batch 83, current loss 0.5812596082687378\n",
      "epoch 1, batch 84, current loss 0.5395311117172241\n",
      "epoch 1, batch 85, current loss 0.540193498134613\n",
      "epoch 1, batch 86, current loss 0.5504695773124695\n",
      "epoch 1, batch 87, current loss 0.5443429350852966\n",
      "epoch 1, batch 88, current loss 0.5951510071754456\n",
      "epoch 1, batch 89, current loss 0.4901506006717682\n",
      "epoch 1, batch 90, current loss 0.5121246576309204\n",
      "epoch 1, batch 91, current loss 0.5164586305618286\n",
      "epoch 1, batch 92, current loss 0.5692868232727051\n",
      "epoch 1, batch 93, current loss 0.516649603843689\n",
      "epoch 1, batch 94, current loss 0.5200204849243164\n",
      "epoch 1, batch 95, current loss 0.5295538306236267\n",
      "epoch 1, batch 96, current loss 0.5502699017524719\n",
      "epoch 1, batch 97, current loss 0.5141034722328186\n",
      "epoch 1, batch 98, current loss 0.5208573341369629\n",
      "epoch 1, batch 99, current loss 0.48651328682899475\n",
      "epoch 1, batch 100, current loss 0.4853287935256958\n",
      "epoch 1, batch 101, current loss 0.5384277701377869\n",
      "epoch 1, batch 102, current loss 0.49230703711509705\n",
      "epoch 1, batch 103, current loss 0.5610459446907043\n",
      "epoch 1, batch 104, current loss 0.46944960951805115\n",
      "epoch 1, batch 105, current loss 0.5542219877243042\n",
      "epoch 1, batch 106, current loss 0.5369299650192261\n",
      "epoch 1, batch 107, current loss 0.5108967423439026\n",
      "epoch 1, batch 108, current loss 0.4930958151817322\n",
      "epoch 1, batch 109, current loss 0.4898250102996826\n",
      "epoch 1, batch 110, current loss 0.4700149595737457\n",
      "epoch 1, batch 111, current loss 0.47619885206222534\n",
      "epoch 1, batch 112, current loss 0.49664172530174255\n",
      "epoch 1, batch 113, current loss 0.4593578279018402\n",
      "epoch 1, batch 114, current loss 0.48634767532348633\n",
      "epoch 1, batch 115, current loss 0.4596309959888458\n",
      "epoch 1, batch 116, current loss 0.5071010589599609\n",
      "epoch 1, batch 117, current loss 0.4649825096130371\n",
      "epoch 1, batch 118, current loss 0.4547666609287262\n",
      "epoch 1, batch 119, current loss 0.4719047248363495\n",
      "epoch 1, batch 120, current loss 0.41376638412475586\n",
      "epoch 1, batch 121, current loss 0.44766294956207275\n",
      "epoch 1, batch 122, current loss 0.51430743932724\n",
      "epoch 1, batch 123, current loss 0.47712862491607666\n",
      "epoch 1, batch 124, current loss 0.3983989655971527\n",
      "epoch 1, batch 125, current loss 0.41480904817581177\n",
      "epoch 1, batch 126, current loss 0.5318464636802673\n",
      "epoch 1, batch 127, current loss 0.4281441569328308\n",
      "epoch 1, batch 128, current loss 0.43621695041656494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, batch 129, current loss 0.47304022312164307\n",
      "epoch 1, batch 130, current loss 0.44413235783576965\n",
      "epoch 1, batch 131, current loss 0.42532768845558167\n",
      "epoch 1, batch 132, current loss 0.4883418083190918\n",
      "epoch 1, batch 133, current loss 0.3542795479297638\n",
      "epoch 1, batch 134, current loss 0.3595634400844574\n",
      "epoch 1, batch 135, current loss 0.441104918718338\n",
      "epoch 1, batch 136, current loss 0.48399782180786133\n",
      "epoch 1, batch 137, current loss 0.45845791697502136\n",
      "epoch 1, batch 138, current loss 0.44914183020591736\n",
      "epoch 1, batch 139, current loss 0.4222983717918396\n",
      "epoch 1, batch 140, current loss 0.4989639222621918\n",
      "epoch 1, batch 141, current loss 0.37319809198379517\n",
      "epoch 1, batch 142, current loss 0.3679457902908325\n",
      "epoch 1, batch 143, current loss 0.4275304973125458\n",
      "epoch 1, batch 144, current loss 0.45655056834220886\n",
      "epoch 1, batch 145, current loss 0.4302317798137665\n",
      "epoch 1, batch 146, current loss 0.4001675546169281\n",
      "epoch 1, batch 147, current loss 0.37193435430526733\n",
      "epoch 1, batch 148, current loss 0.4372040629386902\n",
      "epoch 1, batch 149, current loss 0.4048638641834259\n",
      "epoch 1, batch 150, current loss 0.4141541123390198\n",
      "epoch 1, batch 151, current loss 0.3694927990436554\n",
      "epoch 1, batch 152, current loss 0.39583820104599\n",
      "epoch 1, batch 153, current loss 0.3743113577365875\n",
      "epoch 1, batch 154, current loss 0.3496362864971161\n",
      "epoch 1, batch 155, current loss 0.4356749951839447\n",
      "epoch 1, batch 156, current loss 0.33814793825149536\n",
      "epoch 1, batch 157, current loss 0.3877546191215515\n",
      "epoch 1, batch 158, current loss 0.42423170804977417\n",
      "epoch 1, batch 159, current loss 0.3534056842327118\n",
      "epoch 1, batch 160, current loss 0.46747004985809326\n",
      "epoch 1, batch 161, current loss 0.3355071544647217\n",
      "epoch 1, batch 162, current loss 0.3670807182788849\n",
      "epoch 1, batch 163, current loss 0.35230788588523865\n",
      "epoch 1, batch 164, current loss 0.3930743336677551\n",
      "epoch 1, batch 165, current loss 0.43336862325668335\n",
      "epoch 1, batch 166, current loss 0.45583105087280273\n",
      "epoch 1, batch 167, current loss 0.37686216831207275\n",
      "epoch 1, batch 168, current loss 0.38051819801330566\n",
      "epoch 1, batch 169, current loss 0.479726642370224\n",
      "epoch 1, batch 170, current loss 0.39852258563041687\n",
      "epoch 1, batch 171, current loss 0.4079412817955017\n",
      "epoch 1, batch 172, current loss 0.4927167296409607\n",
      "epoch 1, batch 173, current loss 0.4673359990119934\n",
      "epoch 1, batch 174, current loss 0.3770160973072052\n",
      "epoch 1, batch 175, current loss 0.450834184885025\n",
      "epoch 1, batch 176, current loss 0.4176313281059265\n",
      "epoch 1, batch 177, current loss 0.4177260100841522\n",
      "epoch 1, batch 178, current loss 0.3215784728527069\n",
      "epoch 1, batch 179, current loss 0.385225772857666\n",
      "epoch 1, batch 180, current loss 0.3911309838294983\n",
      "epoch 1, batch 181, current loss 0.35532230138778687\n",
      "epoch 1, batch 182, current loss 0.4655141234397888\n",
      "epoch 1, batch 183, current loss 0.3991759121417999\n",
      "epoch 1, batch 184, current loss 0.3791075348854065\n",
      "epoch 1, batch 185, current loss 0.3767470717430115\n",
      "epoch 1, batch 186, current loss 0.41436100006103516\n",
      "epoch 1, batch 187, current loss 0.357824444770813\n",
      "epoch 1, batch 188, current loss 0.36695370078086853\n",
      "epoch 1, batch 189, current loss 0.3412396013736725\n",
      "epoch 1, batch 190, current loss 0.41315746307373047\n",
      "epoch 1, batch 191, current loss 0.3577978014945984\n",
      "epoch 1, batch 192, current loss 0.3416456878185272\n",
      "epoch 1, batch 193, current loss 0.3916817307472229\n",
      "epoch 1, batch 194, current loss 0.2761308550834656\n",
      "epoch 1, batch 195, current loss 0.3625463843345642\n",
      "epoch 1, batch 196, current loss 0.39092394709587097\n",
      "epoch 1, batch 197, current loss 0.2860237956047058\n",
      "epoch 1, batch 198, current loss 0.38317060470581055\n",
      "epoch 1, batch 199, current loss 0.30762168765068054\n",
      "epoch 1, batch 200, current loss 0.3918735980987549\n",
      "epoch 1, batch 201, current loss 0.34274402260780334\n",
      "epoch 1, batch 202, current loss 0.30838415026664734\n",
      "epoch 1, batch 203, current loss 0.2943660020828247\n",
      "epoch 1, batch 204, current loss 0.30121809244155884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1:\n",
      "Process Process-4:\n",
      "Process Process-3:\n",
      "Process Process-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/share/apps/python3/3.6.3/intel/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/share/apps/python3/3.6.3/intel/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/scratch/zq415/grammar_cor/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/scratch/zq415/grammar_cor/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/scratch/zq415/grammar_cor/Localization/Extract_mouse_data.py\", line 36, in __getitem__\n",
      "    z-box_size:z]\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/share/apps/python3/3.6.3/intel/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/share/apps/python3/3.6.3/intel/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/share/apps/python3/3.6.3/intel/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/scratch/zq415/grammar_cor/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/scratch/zq415/grammar_cor/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/scratch/zq415/grammar_cor/Localization/Extract_mouse_data.py\", line 43, in __getitem__\n",
      "    sample = self.transform(sample)\n",
      "  File \"/scratch/zq415/grammar_cor/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n",
      "  File \"/share/apps/python3/3.6.3/intel/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/scratch/zq415/grammar_cor/Localization/data_augmentation.py\", line 39, in __call__\n",
      "    }[random_choise1](img[0,...])\n",
      "Traceback (most recent call last):\n",
      "  File \"/share/apps/python3/3.6.3/intel/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/scratch/zq415/grammar_cor/Localization/data_augmentation.py\", line 34, in <lambda>\n",
      "    2: lambda x: ndimage.rotate(x,90,(1,2),reshape='True',mode = 'nearest'),\n",
      "  File \"/share/apps/python3/3.6.3/intel/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/scratch/zq415/grammar_cor/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/scratch/zq415/grammar_cor/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/share/apps/python3/3.6.3/intel/lib/python3.6/site-packages/scipy-1.0.0rc1-py3.6-linux-x86_64.egg/scipy/ndimage/interpolation.py\", line 763, in rotate\n",
      "    cval, prefilter)\n",
      "  File \"/share/apps/python3/3.6.3/intel/lib/python3.6/site-packages/scipy-1.0.0rc1-py3.6-linux-x86_64.egg/scipy/ndimage/interpolation.py\", line 486, in affine_transform\n",
      "    output, order, mode, cval, None, None)\n",
      "KeyboardInterrupt\n",
      "  File \"/scratch/zq415/grammar_cor/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/scratch/zq415/grammar_cor/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/scratch/zq415/grammar_cor/Localization/Extract_mouse_data.py\", line 43, in __getitem__\n",
      "    sample = self.transform(sample)\n",
      "  File \"/scratch/zq415/grammar_cor/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n",
      "  File \"/scratch/zq415/grammar_cor/Localization/data_augmentation.py\", line 45, in __call__\n",
      "    }[random_choise2](rotated_img1)\n",
      "  File \"/scratch/zq415/grammar_cor/Localization/data_augmentation.py\", line 44, in <lambda>\n",
      "    4: lambda x: ndimage.rotate(x,270,(0,1),reshape='True',mode = 'nearest')\n",
      "  File \"/share/apps/python3/3.6.3/intel/lib/python3.6/site-packages/scipy-1.0.0rc1-py3.6-linux-x86_64.egg/scipy/ndimage/interpolation.py\", line 763, in rotate\n",
      "    cval, prefilter)\n",
      "  File \"/scratch/zq415/grammar_cor/Localization/Extract_mouse_data.py\", line 43, in __getitem__\n",
      "    sample = self.transform(sample)\n",
      "  File \"/share/apps/python3/3.6.3/intel/lib/python3.6/site-packages/scipy-1.0.0rc1-py3.6-linux-x86_64.egg/scipy/ndimage/interpolation.py\", line 486, in affine_transform\n",
      "    output, order, mode, cval, None, None)\n",
      "KeyboardInterrupt\n",
      "  File \"/scratch/zq415/grammar_cor/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 49, in __call__\n",
      "    img = t(img)\n",
      "  File \"/scratch/zq415/grammar_cor/Localization/data_augmentation.py\", line 45, in __call__\n",
      "    }[random_choise2](rotated_img1)\n",
      "  File \"/scratch/zq415/grammar_cor/Localization/data_augmentation.py\", line 44, in <lambda>\n",
      "    4: lambda x: ndimage.rotate(x,270,(0,1),reshape='True',mode = 'nearest')\n",
      "  File \"/share/apps/python3/3.6.3/intel/lib/python3.6/site-packages/scipy-1.0.0rc1-py3.6-linux-x86_64.egg/scipy/ndimage/interpolation.py\", line 763, in rotate\n",
      "    cval, prefilter)\n",
      "  File \"/share/apps/python3/3.6.3/intel/lib/python3.6/site-packages/scipy-1.0.0rc1-py3.6-linux-x86_64.egg/scipy/ndimage/interpolation.py\", line 486, in affine_transform\n",
      "    output, order, mode, cval, None, None)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-24f495527007>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-24f495527007>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    213\u001b[0m         dataloader = DataLoader(Mouse_dataset, batch_size=args.batch_size,\n\u001b[1;32m    214\u001b[0m                         shuffle=True, num_workers=4)\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Finished Training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     torch.save(net.state_dict(), './model/all_bv_classifier64_c{}_b{}_e{}_v{}.pth'.format(\n",
      "\u001b[0;32m<ipython-input-1-24f495527007>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, criterion, epoch)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;31m# print statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi_batch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch {}, batch {}, current loss {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrunning_loss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "\n",
    "from Extract_mouse_data import Mouse_sub_volumes\n",
    "from data_augmentation import Rotate, Flip\n",
    "from weight_init import weight_init\n",
    "from my_net import VGG_net\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "#####Function and class here\n",
    "def get_subbox_idx(input_idx,input_all_data):\n",
    "    sub_box=[]\n",
    "    neg_num=0\n",
    "    pos_num=0\n",
    "    for idx in input_idx:\n",
    "        for i in range(len(input_all_data[idx][0])):\n",
    "            sub_box.append((idx,0,input_all_data[idx][0][i]))\n",
    "        neg_num+=len(input_all_data[idx][0])\n",
    "        for i in range(len(input_all_data[idx][1])):\n",
    "            sub_box.append((idx,1,input_all_data[idx][1][i]))\n",
    "        pos_num+=len(input_all_data[idx][1])\n",
    "    print(neg_num)\n",
    "    print(pos_num)\n",
    "    print(len(sub_box))\n",
    "    return sub_box\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def train(model, device, train_loader, optimizer, criterion, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i_batch, sample_batched in enumerate(train_loader):\n",
    "        inputs, labels = sample_batched['image'], sample_batched['label']  \n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i_batch % 1 == 0:\n",
    "            print(\"epoch {}, batch {}, current loss {}\".format(epoch+1,i_batch,running_loss/1))\n",
    "            running_loss = 0.0\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    correct_num = 0\n",
    "    total_num = 0\n",
    "    positive_correct=0\n",
    "    positive_num=0\n",
    "    negative_correct=0\n",
    "    negative_num=0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i_batch, sample_batched in enumerate(test_loader):\n",
    "            inputs, labels = sample_batched['image'], sample_batched['label']  \n",
    "            inputs = inputs.to(device)\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_num+=np.sum(predicted.cpu().numpy()==labels.numpy())\n",
    "            total_num+=len(labels)\n",
    "            positive_correct+=np.sum(predicted.cpu().numpy()*labels.numpy())\n",
    "            positive_num+=np.sum(labels.numpy())\n",
    "            negative_correct+=np.sum((1-predicted.cpu().numpy())*(1-labels.numpy()))\n",
    "            negative_num+=np.sum(1-labels.numpy())\n",
    "            \n",
    "    print('total_num:{}, test accuracy:{}, positive_acc:{}, negative_acc:{}'.format(total_num,\n",
    "                                                                                   correct_num/total_num,\n",
    "                                                                                    positive_correct/positive_num,\n",
    "                                                                                    negative_correct/negative_num\n",
    "                                                                                    ))\n",
    "    \n",
    "def test_ensemble(model_list, device, test_loader):\n",
    "    for model in model_list:\n",
    "        model.eval()\n",
    "    #model3.eval()\n",
    "    correct_num = 0\n",
    "    total_num = 0\n",
    "    positive_correct=0\n",
    "    positive_num=0\n",
    "    negative_correct=0\n",
    "    negative_num=0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i_batch, sample_batched in enumerate(test_loader):\n",
    "            inputs, labels = sample_batched['image'], sample_batched['label']  \n",
    "            inputs = inputs.to(device)\n",
    "            # forward + backward + optimize\n",
    "            outputs = model_list[0](inputs)\n",
    "            for i in range(1,len(model_list)):\n",
    "                outputs += model_list[i](inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_num+=np.sum(predicted.cpu().numpy()==labels.numpy())\n",
    "            total_num+=len(labels)\n",
    "            positive_correct+=np.sum(predicted.cpu().numpy()*labels.numpy())\n",
    "            positive_num+=np.sum(labels.numpy())\n",
    "            negative_correct+=np.sum((1-predicted.cpu().numpy())*(1-labels.numpy()))\n",
    "            negative_num+=np.sum(1-labels.numpy())\n",
    "            \n",
    "    print('total_num:{}, test accuracy:{}, positive_acc:{}, negative_acc:{}'.format(total_num,\n",
    "                                                                                   correct_num/total_num,\n",
    "                                                                                    positive_correct/positive_num,\n",
    "                                                                                    negative_correct/negative_num\n",
    "                                                                                    ))\n",
    "\n",
    "\n",
    "\n",
    "def load_data(data_path):\n",
    "    with open(data_path,'rb') as f:\n",
    "        #(neg_subvolumes,pos_subvolumes,img2,filtered_img2,img_label2,data_dic[i][0])\n",
    "        all_data = pickle.load(f)\n",
    "    f.close()\n",
    "    return all_data\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "class Argument():\n",
    "    def __init__(self):\n",
    "        self.batch_size = 200\n",
    "        self.epochs = 5\n",
    "        self.lr = 0.01\n",
    "        self.SGD = True\n",
    "        self.Adam = False\n",
    "        self.RMSprop = False\n",
    "        self.save_version = 1\n",
    "        \n",
    "def main():\n",
    "    # Training settings    \n",
    "    args = Argument()\n",
    "    print(\"batch_size: {}, training epochs: {}, learning rate: {}, SGD {}, Adam {}, RMSprop {}, save_version {}\".\n",
    "         format(args.batch_size, args.epochs, args.lr, args.SGD, args.Adam, args.RMSprop, args.save_version))\n",
    "    \n",
    "    data_path = os.path.join(os.getcwd(),'data','2018_0711_train_sub_volumes2.pickle')\n",
    "    #(neg_subvolumes,pos_subvolumes,img2,filtered_img2, img_label2, \n",
    "    # img, filtered_img, img_label, data_dic[i][0])\n",
    "    all_data = load_data(data_path)\n",
    "    \n",
    "    HALF_SIDE = 64 # half of the bounding size 128\n",
    "    #take 1/6 as test img and the rest as train img\n",
    "    test_idx = list(range(0,len(all_data),6))\n",
    "    total_idx = list(range(len(all_data)))\n",
    "#    train_idx = [x for x in total_idx if x not in test_idx]\n",
    "\n",
    "    print(\"test index: {0}\".format(test_idx))\n",
    "    print(\"train index: {0}\".format(total_idx))\n",
    "    \n",
    "    all_whole_volumes = {}\n",
    "    all_whole_filtered_volumes = {}\n",
    "    for i in range(len(all_data)):\n",
    "        all_whole_volumes[i] = all_data[i][2] - 0.5\n",
    "        all_whole_filtered_volumes[i] = all_data[i][3] - 0.5\n",
    "        \n",
    "    train_sub_box=get_subbox_idx(total_idx,all_data)\n",
    "    test_sub_box=get_subbox_idx(test_idx,all_data)\n",
    "\n",
    "    del all_data\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    net = VGG_net()\n",
    "    #net.apply(weight_init)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        net = nn.DataParallel(net)\n",
    "    net.to(device)\n",
    "    print(\"There are {} parameters in the model\".format(count_parameters(net)))\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss(weight=torch.FloatTensor([1,1.2]).to(device))\n",
    "    if args.SGD == True:\n",
    "        optimizer = optim.SGD(net.parameters(), lr=args.lr, momentum=0.9, weight_decay=0.00001)\n",
    "        print('choose SGD as optimizer')\n",
    "    elif args.Adam == True:\n",
    "        optimizer = optim.Adam(net.parameters(), lr=args.lr*10, weight_decay=0.00001)\n",
    "        print('choose Adam as optimizer')\n",
    "    elif args.RMSprop == True:\n",
    "        optimizer = optim.RMSprop(net.parameters(), lr=args.lr*10, weight_decay=0.00001)\n",
    "        print('choose RMSprop as optimizer')\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "    \n",
    "    for epoch in range(args.epochs):\n",
    "        scheduler.step()\n",
    "        Mouse_dataset = Mouse_sub_volumes(all_whole_volumes,all_whole_filtered_volumes,train_sub_box,\n",
    "                                     transform=transforms.Compose([Rotate(),Flip()]))\n",
    "        dataloader = DataLoader(Mouse_dataset, batch_size=args.batch_size,\n",
    "                        shuffle=True, num_workers=4)\n",
    "        train(net, device, dataloader, optimizer, criterion, epoch)\n",
    "    print('Finished Training')\n",
    "    torch.save(net.state_dict(), './model/all_bv_classifier64_c2_b{}_e{}_v{}.pth'.format(\n",
    "                                                                             args.batch_size,\n",
    "                                                                             args.epochs,\n",
    "                                                                             args.save_version))\n",
    "    #####test\n",
    "    print('train accuracy: ')\n",
    "    Mouse_dataset = Mouse_sub_volumes(all_whole_volumes,all_whole_filtered_volumes,train_sub_box)\n",
    "    train_dataloader = DataLoader(Mouse_dataset, batch_size=args.batch_size,\n",
    "                        shuffle=False, num_workers=4)\n",
    "    test(net, device, train_dataloader)\n",
    "    \n",
    "    print('test accuracy: ')\n",
    "    Mouse_dataset = Mouse_sub_volumes(all_whole_volumes,all_whole_filtered_volumes,test_sub_box)\n",
    "    test_dataloader = DataLoader(Mouse_dataset, batch_size=args.batch_size,\n",
    "                        shuffle=False, num_workers=4)\n",
    "    test(net, device, test_dataloader)\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
