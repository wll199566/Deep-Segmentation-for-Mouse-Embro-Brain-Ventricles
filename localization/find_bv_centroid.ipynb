{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "import nibabel as nib \n",
    "\n",
    "from train_bv_classfier_parse import load_data, get_subbox_idx\n",
    "from my_net import VGG_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_subvolumes(whole_img,whole_label,box_size=64,largest_ratio=0.8,step_size=3):\n",
    "    img_size=np.shape(whole_img)\n",
    "    bv_voxel_num=np.sum(whole_label)\n",
    "    sub_volumes=[]\n",
    "    \n",
    "    x_start = box_size\n",
    "    x_stop = img_size[0]\n",
    "    \n",
    "    y_start = box_size\n",
    "    y_stop = img_size[1]\n",
    "    \n",
    "    z_start = box_size\n",
    "    z_stop = img_size[2]\n",
    "    \n",
    "    for i in range(x_start,x_stop+1,step_size):\n",
    "        for j in range(y_start,y_stop+1,step_size):\n",
    "            for k in range(z_start,z_stop+1,step_size):\n",
    "                if (np.sum(whole_label[i-box_size:i,\n",
    "                                j-box_size:j,\n",
    "                                k-box_size:k])/(bv_voxel_num+0.001)) < largest_ratio:\n",
    "                    sub_volumes.append((0,(i,j,k)))\n",
    "                else:\n",
    "                    sub_volumes.append((1,(i,j,k)))\n",
    "    return sub_volumes\n",
    "\n",
    "class Mouse_sub_volumes(Dataset):\n",
    "    \"\"\"Mouse sub-volumes BV dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, current_whole_volumes, current_whole_filtered_volumes, all_idx, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            all_whole_volumes: Contain all the padded whole BV volumes as a dic\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.whole_volumes = current_whole_volumes\n",
    "        self.idx = all_idx\n",
    "        self.whole_filtered_volumes = current_whole_filtered_volumes\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx)\n",
    "\n",
    "    def __getitem__(self, num):\n",
    "        #idx [0] positive or negative label, [1] x, y, z right corner index\n",
    "        box_size=64\n",
    "        label = self.idx[num][0]\n",
    "        x, y, z = self.idx[num][1]\n",
    "        img = np.zeros((1,box_size,box_size,box_size),np.float32)\n",
    "        \n",
    "        img[0,...] = self.whole_volumes[x-box_size:x,\n",
    "                                        y-box_size:y,\n",
    "                                        z-box_size:z]\n",
    "        \n",
    "        #img[1,...] = self.whole_filtered_volumes[x-box_size:x,\n",
    "        #                                        y-box_size:y,\n",
    "        #                                        z-box_size:z]\n",
    "\n",
    "        sample = {'image': img, 'label': label, 'x': x, 'y': y, 'z': z}\n",
    "        return sample\n",
    "    \n",
    "def save_nii(img, lbl, i, x, y, z, contain_ratio):\n",
    "    box_size = 128\n",
    "    img_nft = nib.Nifti1Image(np.squeeze(img[x-box_size:x, y-box_size:y, z-box_size:z]),np.eye(4))\n",
    "    lbl_nft = nib.Nifti1Image(np.squeeze(lbl[x-box_size:x, y-box_size:y, z-box_size:z]), np.eye(4))\n",
    "    \n",
    "    nib.save(img_nft, './predict/img{}_{}.nii'.format(i, contain_ratio))\n",
    "    nib.save(lbl_nft, './predict/label{}_{}.nii'.format(i, contain_ratio))\n",
    "    \n",
    "def count_contain_ratio(label, box_size, x, y, z):\n",
    "    return (np.sum(label[x-box_size:x,\n",
    "                         y-box_size:y,\n",
    "                         z-box_size:z])/np.sum(label))\n",
    "\n",
    "def test(net1,net2,net3,current_img, current_fil_img, current_label, threshold):\n",
    "    net1.eval()\n",
    "    net2.eval()\n",
    "    net3.eval()\n",
    "    correct_num = 0\n",
    "    total_num = 0\n",
    "    positive_correct=0\n",
    "    positive_num=0\n",
    "    negative_correct=0\n",
    "    negative_num=0\n",
    "    predicted_bv_right_corner = []\n",
    "    true_bv_right_corner = []\n",
    "\n",
    "    current_samples = extract_subvolumes(current_img, current_label)\n",
    "    Mouse_dataset = Mouse_sub_volumes(current_img, current_fil_img, current_samples)\n",
    "    dataloader = DataLoader(Mouse_dataset, batch_size=200, shuffle=False, num_workers=4)\n",
    "    print(\"img_size: {}\".format(current_img.shape))\n",
    "    with torch.no_grad():\n",
    "        for i_batch, sample_batched in enumerate(dataloader):\n",
    "            inputs, labels = sample_batched['image'], sample_batched['label']\n",
    "            right_corner=[]\n",
    "            for ii in range(len(sample_batched['label'])):\n",
    "                right_corner.append((sample_batched['x'][ii],sample_batched['y'][ii],sample_batched['z'][ii]))\n",
    "            inputs = inputs.to(device)\n",
    "            # forward + backward + optimize\n",
    "            outputs = torch.nn.functional.softmax(net1(inputs),dim=1)\n",
    "            outputs += torch.nn.functional.softmax(net2(inputs),dim=1)\n",
    "            outputs += torch.nn.functional.softmax(net3(inputs),dim=1)\n",
    "            outputs /=3.0\n",
    "            outputs[:,0] += threshold\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            for ii in range(len(predicted)):\n",
    "                if predicted[ii]==1:\n",
    "                    predicted_bv_right_corner.append(right_corner[ii])\n",
    "            for ii in range(len(labels)):\n",
    "                if labels[ii]==1:\n",
    "                    true_bv_right_corner.append(right_corner[ii])\n",
    "            \n",
    "            correct_num+=np.sum(predicted.cpu().numpy()==labels.numpy())\n",
    "            total_num+=len(labels)\n",
    "            positive_correct+=np.sum(predicted.cpu().numpy()*labels.numpy())\n",
    "            positive_num+=np.sum(labels.numpy())\n",
    "            negative_correct+=np.sum((1-predicted.cpu().numpy())*(1-labels.numpy()))\n",
    "            negative_num+=np.sum(1-labels.numpy())\n",
    "    return (predicted_bv_right_corner, true_bv_right_corner, correct_num,\n",
    "            total_num, positive_correct, positive_num, negative_correct, negative_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test index: [0, 6, 12, 18, 24, 30]\n",
      "train index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      "Let's use 2 GPUs!\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.join(os.getcwd(),'data','2018_0728_36_test_sub_volumes22.pickle')\n",
    "#(neg_subvolumes,pos_subvolumes,img2,filtered_img2, img_label2, \n",
    "# img, filtered_img, img_label, data_dic[i][0])\n",
    "all_data = load_data(data_path)\n",
    "\n",
    "HALF_SIDE = 64 # half of the bounding size 128\n",
    "#take 1/6 as test img and the rest as train img\n",
    "test_idx = list(range(0,len(all_data),6))\n",
    "total_idx = list(range(len(all_data)))\n",
    "print(\"test index: {0}\".format(test_idx))\n",
    "print(\"train index: {0}\".format(total_idx))\n",
    "\n",
    "all_whole_volumes = {}\n",
    "all_whole_filtered_volumes = {}\n",
    "all_whole_labels = {}\n",
    "for i in range(len(all_data)):\n",
    "    all_whole_volumes[i] = all_data[i][2] -0.5\n",
    "    all_whole_filtered_volumes[i] = all_data[i][3] - 0.5\n",
    "    all_whole_labels[i] = all_data[i][4]\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net1 = VGG_net()\n",
    "net2 = VGG_net()\n",
    "net3 = VGG_net()\n",
    "\n",
    "#net.apply(weight_init)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    net1 = nn.DataParallel(net1)\n",
    "    net2 = nn.DataParallel(net2)\n",
    "    net3 = nn.DataParallel(net3)\n",
    "net1.to(device)\n",
    "net2.to(device)\n",
    "net3.to(device)\n",
    "net1.load_state_dict(torch.load('./model/all_bv_classifier64_c1_b200_e7_v1.pth'))\n",
    "net2.load_state_dict(torch.load('./model/all_bv_classifier64_c1_b200_e6_v1.pth'))\n",
    "net3.load_state_dict(torch.load('./model/all_bv_classifier64_c1_b200_e5_v1.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_size: (75, 101, 101)\n",
      "count: 1, true_right_corner: [ 68.5         85.69863014  91.45205479], predicted_right_corner: [ 68.5  88.   95.5]\n",
      "Contain ratio 0: 1.0, Contain ratio 1: 1.0\n",
      "total_num:676, test accuracy:0.7810650887573964, positive_acc:0.4931506849315068, negative_acc:1.0\n",
      "  \n",
      "img_size: (75, 101, 101)\n",
      "count: 2, true_right_corner: [ 68.5  82.   92.5], predicted_right_corner: [ 68.49372385  83.43096234  94.0251046 ]\n",
      "Contain ratio 0: 1.0, Contain ratio 1: 1.0\n",
      "total_num:676, test accuracy:0.8920118343195266, positive_acc:0.7660256410256411, negative_acc:1.0\n",
      "  \n",
      "img_size: (75, 111, 81)\n",
      "count: 3, true_right_corner: [  68.5    100.375   71.125], predicted_right_corner: [  68.5   103.25   69.75]\n",
      "Contain ratio 0: 1.0, Contain ratio 1: 1.0\n",
      "total_num:384, test accuracy:0.8333333333333334, positive_acc:0.6, negative_acc:1.0\n",
      "  \n",
      "img_size: (75, 111, 91)\n",
      "count: 4, true_right_corner: [ 68.5         90.4516129   82.38709677], predicted_right_corner: [ 68.65957447  91.2393617   85.97340426]\n",
      "Contain ratio 0: 1.0, Contain ratio 1: 1.0\n",
      "total_num:640, test accuracy:0.7125, positive_acc:0.5053763440860215, negative_acc:1.0\n",
      "  \n",
      "img_size: (75, 111, 71)\n",
      "count: 5, true_right_corner: [ 68.5  76.   67. ], predicted_right_corner: [ 68.6  73.8  67.1]\n",
      "Contain ratio 0: 1.0, Contain ratio 1: 1.0\n",
      "total_num:192, test accuracy:0.90625, positive_acc:0.8333333333333334, negative_acc:1.0\n",
      "  \n",
      "img_size: (75, 111, 101)\n",
      "count: 6, true_right_corner: [  68.5     100.1875   72.8125], predicted_right_corner: [ 68.64102564  99.76923077  73.8974359 ]\n",
      "Contain ratio 0: 1.0, Contain ratio 1: 1.0\n",
      "total_num:832, test accuracy:0.8810096153846154, positive_acc:0.546875, negative_acc:0.98125\n",
      "  \n",
      "img_size: (90, 121, 121)\n",
      "count: 7, true_right_corner: [  76.           69.79310345  113.75862069], predicted_right_corner: [  76.    68.5  115. ]\n",
      "Contain ratio 0: 1.0, Contain ratio 1: 1.0\n",
      "total_num:3600, test accuracy:0.9775, positive_acc:0.6896551724137931, negative_acc:1.0\n",
      "  \n",
      "img_size: (105, 121, 141)\n",
      "count: 8, true_right_corner: [ 87.93364929  84.52764613  80.11690363], predicted_right_corner: [ 87.15420561  82.64485981  77.36448598]\n",
      "Contain ratio 0: 1.0, Contain ratio 1: 1.0\n",
      "total_num:7280, test accuracy:0.915521978021978, positive_acc:0.6761453396524486, negative_acc:1.0\n",
      "  \n",
      "img_size: (105, 121, 141)\n",
      "count: 9, true_right_corner: [ 88.3712297   85.40835267  74.23201856], predicted_right_corner: [ 88.67411301  83.60446781  71.53745072]\n",
      "Contain ratio 0: 1.0, Contain ratio 1: 1.0\n",
      "total_num:7280, test accuracy:0.926923076923077, positive_acc:0.588553750966744, negative_acc:1.0\n",
      "  \n",
      "img_size: (90, 121, 141)\n",
      "count: 10, true_right_corner: [ 76.          98.57664234  79.70072993], predicted_right_corner: [ 75.97011208  97.2241594   77.15442092]\n",
      "Contain ratio 0: 1.0, Contain ratio 1: 1.0\n",
      "total_num:4680, test accuracy:0.9081196581196581, positive_acc:0.6512570965125709, negative_acc:1.0\n",
      "  \n",
      "img_size: (90, 121, 121)\n",
      "count: 11, true_right_corner: [ 83.69273743  96.09497207  73.92178771], predicted_right_corner: [ 83.368  95.688  72.584]\n",
      "Contain ratio 0: 1.0, Contain ratio 1: 1.0\n",
      "total_num:3600, test accuracy:0.9455555555555556, positive_acc:0.6666666666666666, negative_acc:0.9944498857329416\n",
      "  \n",
      "img_size: (90, 121, 121)\n",
      "count: 12, true_right_corner: [ 78.23728814  95.00308166  69.62557781], predicted_right_corner: [ 78.33742331  94.72699387  66.94478528]\n",
      "Contain ratio 0: 1.0, Contain ratio 1: 1.0\n",
      "total_num:3600, test accuracy:0.9102777777777777, positive_acc:0.50231124807396, negative_acc:1.0\n",
      "  \n",
      "img_size: (90, 121, 121)\n",
      "count: 13, true_right_corner: [  76.           69.79310345  113.75862069], predicted_right_corner: [  75.93220339   68.42372881  115.10169492]\n",
      "Contain ratio 0: 1.0, Contain ratio 1: 1.0\n",
      "total_num:3600, test accuracy:0.9766666666666667, positive_acc:0.6781609195402298, negative_acc:1.0\n",
      "  \n",
      "img_size: (90, 121, 121)\n",
      "count: 14, true_right_corner: [  72.69318182   81.82954545  113.67045455], predicted_right_corner: [  72.89156627   80.30120482  115.        ]\n",
      "Contain ratio 0: 1.0, Contain ratio 1: 1.0\n",
      "total_num:3600, test accuracy:0.9686111111111111, positive_acc:0.7859848484848485, negative_acc:1.0\n",
      "  \n",
      "img_size: (90, 121, 121)\n",
      "count: 15, true_right_corner: [  75.71547421   83.02329451  115.23460899], predicted_right_corner: [  75.49885584   81.27231121  116.6819222 ]\n",
      "Contain ratio 0: 1.0, Contain ratio 1: 1.0\n",
      "total_num:3600, test accuracy:0.9544444444444444, positive_acc:0.7271214642262895, negative_acc:1.0\n",
      "  \n",
      "img_size: (90, 121, 101)\n",
      "count: 16, true_right_corner: [ 76.03003755  75.83854819  77.31789737], predicted_right_corner: [ 76.16304348  72.9673913   75.64130435]\n",
      "Contain ratio 0: 1.0, Contain ratio 1: 1.0\n",
      "total_num:2340, test accuracy:0.8944444444444445, positive_acc:0.690863579474343, negative_acc:1.0\n",
      "  \n",
      "img_size: (90, 121, 121)\n",
      "count: 17, true_right_corner: [  75.85509434  109.30792453   88.53660377], predicted_right_corner: [  75.88325472  108.92216981   89.13207547]\n",
      "Contain ratio 0: 1.0, Contain ratio 1: 1.0\n",
      "total_num:3600, test accuracy:0.8636111111111111, positive_acc:0.6347169811320754, negative_acc:0.9969230769230769\n",
      "  \n",
      "img_size: (90, 121, 121)\n",
      "count: 18, true_right_corner: [ 76.       76.96875  77.25   ], predicted_right_corner: [ 76.01410658  74.57523511  75.59090909]\n",
      "Contain ratio 0: 0.9979013641133263, Contain ratio 1: 0.9989067624550991\n",
      "total_num:3600, test accuracy:0.9372222222222222, positive_acc:0.7384259259259259, negative_acc:1.0\n",
      "  \n",
      "img_size: (90, 121, 121)\n",
      "count: 19, true_right_corner: [  76.10619469   69.78761062  111.15044248], predicted_right_corner: [  77.65240642   68.28342246  113.7486631 ]\n",
      "Contain ratio 0: 1.0, Contain ratio 1: 1.0\n",
      "total_num:3600, test accuracy:0.9577777777777777, positive_acc:0.551622418879056, negative_acc:1.0\n",
      "  \n",
      "img_size: (90, 121, 121)\n",
      "count: 20, true_right_corner: [  76.          109.55813953  115.20930233], predicted_right_corner: [  76.32188841  110.58369099  117.56223176]\n",
      "Contain ratio 0: 1.0, Contain ratio 1: 1.0\n",
      "total_num:3600, test accuracy:0.9572222222222222, positive_acc:0.6020671834625323, negative_acc:1.0\n",
      "  \n",
      "img_size: (90, 121, 111)\n",
      "count: 21, true_right_corner: [  76.0438247   104.56175299   72.96414343], predicted_right_corner: [  77.62178218  106.27326733   71.15841584]\n",
      "Contain ratio 0: 1.0, Contain ratio 1: 1.0\n",
      "total_num:2880, test accuracy:0.9138888888888889, positive_acc:0.6706507304116865, negative_acc:1.0\n",
      "  \n",
      "img_size: (90, 121, 101)\n",
      "count: 22, true_right_corner: [ 72.08554217  92.82168675  76.72650602], predicted_right_corner: [ 70.36255924  95.32227488  74.27251185]\n",
      "Contain ratio 0: 1.0, Contain ratio 1: 1.0\n",
      "total_num:2340, test accuracy:0.8256410256410256, positive_acc:0.5084337349397591, negative_acc:1.0\n",
      "  \n",
      "img_size: (90, 121, 111)\n",
      "count: 23, true_right_corner: [  76.    85.2  100.1], predicted_right_corner: [  75.23415493   86.27288732  101.70070423]\n",
      "Contain ratio 0: 1.0, Contain ratio 1: 1.0\n",
      "total_num:2880, test accuracy:0.9159722222222222, positive_acc:0.7012345679012346, negative_acc:1.0\n",
      "  \n",
      "img_size: (90, 121, 121)\n",
      "count: 24, true_right_corner: [  75.88679245  106.1163522   108.00628931], predicted_right_corner: [  75.35427807  106.04411765  110.69251337]\n",
      "Contain ratio 0: 1.0, Contain ratio 1: 1.0\n",
      "total_num:3600, test accuracy:0.9427777777777778, positive_acc:0.7840670859538784, negative_acc:1.0\n",
      "  \n",
      "img_size: (90, 121, 101)\n",
      "count: 25, true_right_corner: [ 75.30059172  85.39408284  90.10177515], predicted_right_corner: [ 73.6         86.50967742  92.77419355]\n",
      "Contain ratio 0: 1.0, Contain ratio 1: 1.0\n",
      "total_num:2340, test accuracy:0.8282051282051283, positive_acc:0.5372781065088758, negative_acc:0.9926421404682274\n",
      "  \n",
      "img_size: (90, 121, 121)\n",
      "count: 26, true_right_corner: [  75.8572973   104.80972973   75.42918919], predicted_right_corner: [  75.72525849  106.0620384    72.80502216]\n",
      "Contain ratio 0: 1.0, Contain ratio 1: 1.0\n",
      "total_num:3600, test accuracy:0.9311111111111111, positive_acc:0.7318918918918919, negative_acc:1.0\n",
      "  \n",
      "img_size: (90, 121, 121)\n",
      "count: 27, true_right_corner: [  71.93229167  104.15625      94.31510417], predicted_right_corner: [  69.54809437  104.61161525   94.36479129]\n",
      "Contain ratio 0: 1.0, Contain ratio 1: 1.0\n",
      "total_num:3600, test accuracy:0.8302777777777778, positive_acc:0.4739583333333333, negative_acc:0.9979575163398693\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_size: (90, 121, 111)\n",
      "count: 28, true_right_corner: [  76.          101.05882353   71.10294118], predicted_right_corner: [  75.82044888  100.84538653   68.96758105]\n",
      "Contain ratio 0: 1.0, Contain ratio 1: 1.0\n",
      "total_num:2880, test accuracy:0.9267361111111111, positive_acc:0.6552287581699346, negative_acc:1.0\n",
      "  \n",
      "img_size: (90, 121, 121)\n",
      "count: 29, true_right_corner: [  74.24875267  103.33143264  102.03777619], predicted_right_corner: [  74.36623377  103.91948052  104.91948052]\n",
      "Contain ratio 0: 1.0, Contain ratio 1: 1.0\n",
      "total_num:3600, test accuracy:0.9205555555555556, positive_acc:0.8096935138987883, negative_acc:0.9913518434228493\n",
      "  \n",
      "img_size: (90, 121, 101)\n",
      "count: 30, true_right_corner: [  80.97637795  105.62992126   70.88188976], predicted_right_corner: [  79.5221843   102.75426621   71.8225256 ]\n",
      "Contain ratio 0: 0.9893469198703103, Contain ratio 1: 0.9941320499831138\n",
      "total_num:2340, test accuracy:0.917094017094017, positive_acc:0.6299212598425197, negative_acc:0.9729453802960695\n",
      "  \n",
      "img_size: (90, 121, 101)\n",
      "count: 31, true_right_corner: [ 75.28337237  85.15105386  89.91451991], predicted_right_corner: [ 73.27   85.624  92.152]\n",
      "Contain ratio 0: 1.0, Contain ratio 1: 1.0\n",
      "total_num:2340, test accuracy:0.8444444444444444, positive_acc:0.5796252927400468, negative_acc:0.9966352624495289\n",
      "  \n",
      "img_size: (90, 121, 121)\n",
      "count: 32, true_right_corner: [ 80.51842752  92.54054054  71.04668305], predicted_right_corner: [ 82.17105263  95.25        69.36842105]\n",
      "Contain ratio 0: 1.0, Contain ratio 1: 1.0\n",
      "total_num:3600, test accuracy:0.9502777777777778, positive_acc:0.5601965601965602, negative_acc:1.0\n",
      "  \n",
      "img_size: (90, 121, 121)\n",
      "count: 33, true_right_corner: [  74.16744809  102.24849297  101.91694575], predicted_right_corner: [  74.34251291  103.94234079  104.51290878]\n",
      "Contain ratio 0: 1.0, Contain ratio 1: 1.0\n",
      "total_num:3600, test accuracy:0.8991666666666667, positive_acc:0.7675820495646349, negative_acc:0.992406264831514\n",
      "  \n",
      "img_size: (90, 121, 111)\n",
      "count: 34, true_right_corner: [ 73.40077821  94.31906615  98.30350195], predicted_right_corner: [  71.35698448   94.32594235  101.60310421]\n",
      "Contain ratio 0: 1.0, Contain ratio 1: 1.0\n",
      "total_num:2880, test accuracy:0.8888888888888888, positive_acc:0.5849546044098574, negative_acc:1.0\n",
      "  \n",
      "img_size: (90, 121, 111)\n",
      "count: 35, true_right_corner: [  75.47166922  104.6906585   101.10719755], predicted_right_corner: [  74.20300752  105.7443609   103.60902256]\n",
      "Contain ratio 0: 1.0, Contain ratio 1: 1.0\n",
      "total_num:2880, test accuracy:0.9118055555555555, positive_acc:0.6110260336906586, negative_acc:1.0\n",
      "  \n",
      "img_size: (90, 121, 111)\n",
      "count: 36, true_right_corner: [  72.77433628  100.02323009   75.4590708 ], predicted_right_corner: [  72.75712144  101.63268366   72.81109445]\n",
      "Contain ratio 0: 1.0, Contain ratio 1: 1.0\n",
      "total_num:2880, test accuracy:0.9170138888888889, positive_acc:0.7367256637168141, negative_acc:0.9994939271255061\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "########for validation data\n",
    "count=0\n",
    "\n",
    "all_predic_bv_right_corner = np.zeros((len(total_idx),3))\n",
    "all_true_bv_right_corner = np.zeros((len(total_idx),3))\n",
    "contain_ratio = np.zeros((len(total_idx),2))\n",
    "\n",
    "wrong_idx = []\n",
    "test_sub_box = {}\n",
    "\n",
    "for current_idx in total_idx:            \n",
    "    (predicted_bv_right_corner, true_bv_right_corner,\n",
    "     correct_num, total_num, positive_correct, positive_num,\n",
    "     negative_correct, negative_num) = test(net1, net2, net3, all_whole_volumes[current_idx],\n",
    "                                            all_whole_filtered_volumes[current_idx],\n",
    "                                            all_whole_labels[current_idx], 0.9)\n",
    "    if len(predicted_bv_right_corner) == 0:\n",
    "        (predicted_bv_right_corner, true_bv_right_corner,\n",
    "         correct_num, total_num, positive_correct, positive_num,\n",
    "         negative_correct, negative_num) = test(net1, net2, net3, all_whole_volumes[current_idx],\n",
    "                                                all_whole_filtered_volumes[current_idx],\n",
    "                                                all_whole_labels[current_idx], 0.8)\n",
    "    if len(predicted_bv_right_corner) == 0:\n",
    "        (predicted_bv_right_corner, true_bv_right_corner,\n",
    "         correct_num, total_num, positive_correct, positive_num,\n",
    "         negative_correct, negative_num) = test(net1, net2, net3, all_whole_volumes[current_idx],\n",
    "                                                all_whole_filtered_volumes[current_idx],\n",
    "                                                all_whole_labels[current_idx], 0.7)\n",
    "   \n",
    "    for ii in range(len(predicted_bv_right_corner)):\n",
    "        all_predic_bv_right_corner[count,:]+=predicted_bv_right_corner[ii]\n",
    "    all_predic_bv_right_corner[count,:]/=len(predicted_bv_right_corner)\n",
    "    \n",
    "    for ii in range(len(true_bv_right_corner)):\n",
    "        all_true_bv_right_corner[count,:]+=true_bv_right_corner[ii]\n",
    "    all_true_bv_right_corner[count,:]/=len(true_bv_right_corner)\n",
    "    \n",
    "    x, y, z = (int(all_predic_bv_right_corner[count,0]), \n",
    "                    int(all_predic_bv_right_corner[count,1]), \n",
    "                    int(all_predic_bv_right_corner[count,2]))\n",
    "    contain_ratio[count,0] = count_contain_ratio(all_whole_labels[current_idx], HALF_SIDE, x, y, z)\n",
    "    \n",
    "    x2, y2, z2 = (int(2*all_predic_bv_right_corner[count,0]), \n",
    "                    int(2*all_predic_bv_right_corner[count,1]), \n",
    "                    int(2*all_predic_bv_right_corner[count,2]))\n",
    "    test_sub_box[current_idx] = (all_data[current_idx][5],all_data[current_idx][6],all_data[current_idx][7],\n",
    "                                x2,y2,z2)\n",
    "    \n",
    "    contain_ratio[count,1] = count_contain_ratio(all_data[current_idx][7], HALF_SIDE*2, x2, y2, z2)\n",
    "\n",
    "    save_nii(all_data[current_idx][5],\n",
    "             all_data[current_idx][7],\n",
    "             count+1, x2, y2 ,z2, contain_ratio[count,1])\n",
    "    if contain_ratio[count,1] < 0.997:\n",
    "        wrong_idx.append((count,i,contain_ratio[count,1]))\n",
    "   \n",
    "    if negative_num == 0:\n",
    "        negative_num+=1\n",
    "    count+=1\n",
    "    print(\"count: {}, true_right_corner: {}, predicted_right_corner: {}\".format(count,\n",
    "                                                                        all_true_bv_right_corner[count-1,:], \n",
    "                                                         \n",
    "                                                                                all_predic_bv_right_corner[count-1,:]))\n",
    "    print(\"Contain ratio 0: {}, Contain ratio 1: {}\".format(contain_ratio[count-1,0],contain_ratio[count-1,1]))\n",
    "    print('total_num:{}, test accuracy:{}, positive_acc:{}, negative_acc:{}'.format(total_num,\n",
    "                                                                                   correct_num/total_num,\n",
    "                                                                                    positive_correct/positive_num,\n",
    "                                                                                    negative_correct/negative_num\n",
    "                                                                                   ))\n",
    "    print(\"  \")\n",
    "save_name = 'test_predict_c1_v2_36.pickle'\n",
    "save_file = open(os.path.join(os.getcwd(),'data',save_name),'wb')\n",
    "pickle.dump(test_sub_box,save_file)\n",
    "save_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wrong_idx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f77e5a20c785>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwrong_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'wrong_idx' is not defined"
     ]
    }
   ],
   "source": [
    "wrong_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
